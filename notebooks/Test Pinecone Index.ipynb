{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Dam Response\\\\jgeot.17.p.095.pdf, G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Structural Analysis\\\\Behaviour of the reinforced concrete face slabs of concrete faced rockfill dams during impounding.pdf, G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Dam Response\\\\jgeot.17.p.095.pdf, G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Numerical Analysis\\\\Fu2019_Article_AGeneralizedPlasticityModelFor.pdf'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinecone\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "# Set your Pinecone API key\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone.init(api_key=api_key, environment=\"us-central1-gcp\")\n",
    "\n",
    "\n",
    "# Get the index \n",
    "pinecone.list_indexes()\n",
    "\n",
    "\n",
    "pinecone.describe_index(\"icold\")\n",
    "index_name = \"icold\"\n",
    "index = pinecone.GRPCIndex(index_name)\n",
    "\n",
    "index.describe_index_stats()\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n",
    "query = \"what is a cfrd?\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=5  # return 3 most relevant docs\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "qa.run(query)\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "response = qa_with_sources(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
