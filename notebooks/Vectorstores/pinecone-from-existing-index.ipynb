{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"CFRD Knowledge Base\")\n",
    "st.info(\"\"\"I am a knowledgeable chatbot with extensive information about Concrete Face Rockfill Dams (CFRDs). \n",
    "        I can answer questions about CFRDs, and I can also summarize the contents of a PDF file.\"\"\")\n",
    "# set up pinecone\n",
    "import pinecone\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "pinecone.init(api_key='48640420-7e79-46d4-b71d-d07286818fef', environment='us-central1-gcp')\n",
    "\n",
    "index_name = 'icold'\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "index = pinecone.Index(index_name, embeddings)\n",
    "\n",
    "query = st.text_input(\"Ask me a question about CFRDs\", \"\")\n",
    "query = \"how to estimate leakage through a cfrd?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query != \"\":\n",
    "    index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 8100}},\n",
       " 'total_vector_count': 8100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 2000\n",
    "\n",
    "def retrieve(query):\n",
    "    \"\"\"\n",
    "    This function retrieves the top 10 most relevant contexts from the index\n",
    "    \"\"\"\n",
    "    # Create a vector from the query\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=10, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "    \n",
    "    sources = [x['metadata']['source'] for x in res['matches']]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"\"\"\n",
    "        Answer the question based on the context below. Be as detailed as possible but do not\n",
    "        provide information that is not in the context. Do provide as much relevant context in the response as possible.\\n\\n\"\"\"\n",
    "        +\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt, sources, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    llm = ChatOpenAI(temperature=0.5, max_tokens=400)\n",
    "    from langchain.chains import RetrievalQA\n",
    "    \n",
    "    # Create a vector from an existing index\n",
    "    docsearch = Pinecone.from_existing_index('icold', embeddings, \n",
    "                                         )\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    )\n",
    "    \n",
    "    lang = 'EN'\n",
    "\n",
    "    I=0\n",
    "    query = \"Como se comportan los cfrd durange los terremotos?\"\n",
    "\n",
    "    def run_retrieval(query):\n",
    "        return qa({\"query\": query + f\". Answer in {lang} language with examples of actual dams as possible from the context. Do not mention that there was a context provided.\", \"n\": 1})\n",
    "    result = run_retrieval(query)\n",
    "\n",
    "    print(pretty_print(result[\"result\"]))\n",
    "\n",
    "    return res['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(response):\n",
    "    \"\"\"\n",
    "    Print a new line every 80 characters\n",
    "    \"\"\"\n",
    "    for i in range(0, len(response), 150):\n",
    "        print(response[i:i+150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cracking of the Campos Novos dam is believed to be caused by the differing support to the face slab and the collapse as a result of progressive er\n",
      "osion within the Zone 2B. Additionally, the changing water level was the main cause of cracking in the face slab of the dam. Horizontal cracks were li\n",
      "kely caused by a short period of rapid cooling or insulation failure.\n"
     ]
    }
   ],
   "source": [
    "query = \"what caused the cracking of the campos novos dam?\"\n",
    "query_with_contexts, sources, contexts = retrieve(query)\n",
    "pretty_print(complete(query_with_contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of the concrete face connected. In addition, at this location, the foundation rock slopes\n",
      "\n",
      "steeply downward. It is believed that the initial cause of the cracks is the differing\n",
      "\n",
      "support to the face slab and the collapse as a result of progressive erosion within the\n",
      "\n",
      "Zone 2B.\n",
      "\n",
      "In November 2000, 16 years after first filling of the reservoir, leakage suddenly\n",
      "\n",
      "increased from a stable 100 l/s to 900 l/s. Within two weeks, leakage had increased to\n",
      "\n",
      "2 200 l/s. The leakage source was at mid-height of the dam where the dam is 90 m tall.\n"
     ]
    }
   ],
   "source": [
    "print(contexts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\B141.pdf'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 l/s\n"
     ]
    }
   ],
   "source": [
    "query = \"what leakage rate was reported in the campos novos dam upon impounding?\"\n",
    "query_with_contexts, sources = retrieve(query)\n",
    "pretty_print(complete(query_with_contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Structural Analysis\\\\(ASCE)GM.1943-5622.0000478.pdf',\n",
       " 'G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\B141.pdf',\n",
       " 'G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Structural Analysis\\\\jmacr.16.00367.pdf',\n",
       " 'G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Structural Analysis\\\\jmacr.16.00367.pdf',\n",
       " 'G:\\\\.shortcut-targets-by-id\\\\1vE28d8xZuJXkpcinFbuku9FJgeaDd48K\\\\ICOLD - CFRD New Bulletin 2023\\\\Dam Response\\\\Monitoring System.pdf']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
